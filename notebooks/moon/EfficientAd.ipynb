{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f61cbd",
   "metadata": {
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1770009243966,
     "user": {
      "displayName": "ë¬¸êµ­í˜„",
      "userId": "05772362328087904375"
     },
     "user_tz": -540
    },
    "id": "e6f61cbd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import sys\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af721de4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3925,
     "status": "ok",
     "timestamp": 1770009247892,
     "user": {
      "displayName": "ë¬¸êµ­í˜„",
      "userId": "05772362328087904375"
     },
     "user_tz": -540
    },
    "id": "af721de4",
    "outputId": "0f7c77e8-50fe-4d83-b391-31958477cae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/mungughyeon/Documents/Bootcamp/Likelion/multiModal_anomaly_report\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    !uv pip install anomalib\n",
    "    !uv pip install open-clip-torch\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    PROJECT_ROOT = Path('/content/drive/Othercomputers/Mac/multiModal_anomaly_report') # ë³¸ì¸ ê²½ë¡œ ìˆ˜ì •: Mac/Window\n",
    "except ImportError:\n",
    "    PROJECT_ROOT = Path.cwd().parents[1]\n",
    "\n",
    "os.chdir(PROJECT_ROOT) # í˜„ì¬ ê²½ë¡œ ìˆ˜ì •\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e166a162",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1770009247895,
     "user": {
      "displayName": "ë¬¸êµ­í˜„",
      "userId": "05772362328087904375"
     },
     "user_tz": -540
    },
    "id": "e166a162"
   },
   "outputs": [],
   "source": [
    "# TODO: PATH ì„¤ì •\n",
    "\n",
    "# dataset path\n",
    "DATA_ROOT = PROJECT_ROOT / \"dataset\" / \"MMAD\"\n",
    "DOMAIN_JSON = DATA_ROOT / \"domain_knowledge.json\"\n",
    "MMAD_JSON = DATA_ROOT / \"mmad.json\"\n",
    "META_CSV = DATA_ROOT / \"metadata.csv\"\n",
    "\n",
    "# config.yaml path\n",
    "CONFIG_ROOT = PROJECT_ROOT / \"configs\"\n",
    "RUNTIME_CONFIG_ROOT = CONFIG_ROOT / \"runtime.yaml\"\n",
    "EVAL_CONFIG_ROOT = CONFIG_ROOT / \"eval.yaml\"\n",
    "\n",
    "# output path\n",
    "OUTPUT_ROOT = PROJECT_ROOT / \"output\"\n",
    "\n",
    "# check (ì„ íƒì‚¬í•­)\n",
    "# print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "# print(f\"Data Root: {DATA_ROOT}\")\n",
    "# print(f\"Config Root: {CONFIG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d32f3d",
   "metadata": {
    "id": "a4d32f3d"
   },
   "source": [
    "### MVTecAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95d261",
   "metadata": {
    "executionInfo": {
     "elapsed": 8659,
     "status": "ok",
     "timestamp": 1770009256950,
     "user": {
      "displayName": "ë¬¸êµ­í˜„",
      "userId": "05772362328087904375"
     },
     "user_tz": -540
    },
    "id": "9b95d261"
   },
   "outputs": [],
   "source": [
    "from src.utils import load_config, load_json, load_csv\n",
    "from anomalib.data import MVTecAD\n",
    "from anomalib.models import EfficientAd\n",
    "from anomalib.engine import Engine\n",
    "\n",
    "# TODO: runtime_config.yaml í™•ì¥/ìˆ˜ì •\n",
    "runtime_config = load_config(RUNTIME_CONFIG_ROOT)\n",
    "domain_json = load_json(DOMAIN_JSON)\n",
    "mmad_json = load_json(MMAD_JSON)\n",
    "meta_csv = load_csv(META_CSV)\n",
    "\n",
    "# tqdm bar off\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "categories = [\n",
    "    \"bottle\", \"cable\", \"capsule\", \"carpet\", \"grid\",\n",
    "    \"hazelnut\", \"leather\", \"metal_nut\", \"pill\", \"screw\",\n",
    "    \"tile\", \"toothbrush\", \"transistor\", \"wood\", \"zipper\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1652a165",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "1652a165",
    "outputId": "43122bda-7962-4ad5-bd27-2f59d872ef7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/15] Testing: bottle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:lightning_fabric.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning_fabric.utilities.rank_zero:ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning_fabric.utilities.rank_zero:The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9865078926086426     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9677419066429138     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8568322658538818     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.4932612180709839     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9865078926086426    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9677419066429138    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8568322658538818    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.4932612180709839    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ [1/15] bottle ì™„ë£Œ (122.8s)\n",
      "\n",
      "[2/15] Testing: cable...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:lightning_fabric.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning_fabric.utilities.rank_zero:ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning_fabric.utilities.rank_zero:The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for i, category in enumerate(categories, 1):\n",
    "    print(f\"\\n[{i}/{len(categories)}] Testing: {category}...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    datamodule = MVTecAD(\n",
    "        root=DATA_ROOT / \"MVTec-AD\",\n",
    "        category=category\n",
    "    )\n",
    "\n",
    "    model = EfficientAd()\n",
    "    engine = Engine(\n",
    "        logger=False,\n",
    "        enable_progress_bar=False,\n",
    "        accelerator=\"auto\", # cpu, mps\n",
    "        devices=1,\n",
    "        default_root_dir=OUTPUT_ROOT\n",
    "    )\n",
    "\n",
    "    engine.fit(datamodule=datamodule, model=model);\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"âœ“ [{i}/{len(categories)}] {category} ì™„ë£Œ ({elapsed:.1f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82638b4d",
   "metadata": {
    "id": "82638b4d"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "# # tqdm bar on\n",
    "# os.environ.pop(\"TQDM_DISABLE\", None)\n",
    "\n",
    "categories = [\n",
    "    \"bottle\", \"cable\", \"capsule\", \"carpet\", \"grid\",\n",
    "    \"hazelnut\", \"leather\", \"metal_nut\", \"pill\", \"screw\",\n",
    "    \"tile\", \"toothbrush\", \"transistor\", \"wood\", \"zipper\"\n",
    "]\n",
    "\n",
    "all_predictions = {}\n",
    "for i, category in enumerate(categories, 1):\n",
    "    print(f\"[{i}/{len(categories)}] Inference: {category}\")\n",
    "    # ckpt_path = OUTPUT_ROOT / category / \"v0/weights/lightning/model.ckpt\"\n",
    "    ckpt_path = OUTPUT_ROOT / \"EfficientAd\" / \"MVTecAD\" / category / \"v0/weights/lightning/model.ckpt\"\n",
    "\n",
    "    datamodule = MVTecAD(\n",
    "          root=DATA_ROOT / \"MVTec-AD\",\n",
    "          category=category\n",
    "    )\n",
    "\n",
    "    model = EfficientAd()\n",
    "    engine = Engine(\n",
    "        logger=False,\n",
    "        enable_progress_bar=False,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        default_root_dir=OUTPUT_ROOT\n",
    "    )\n",
    "\n",
    "    predictions = engine.predict(\n",
    "        datamodule=datamodule,\n",
    "        model=model,\n",
    "        ckpt_path=ckpt_path,\n",
    "    )\n",
    "\n",
    "    all_predictions[category] = predictions\n",
    "    print(f\"âœ“ [{i}/{len(categories)}] {category} ì™„ë£Œ\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b5cfc",
   "metadata": {
    "id": "551b5cfc"
   },
   "outputs": [],
   "source": [
    "from src.visual.plot import kde_plot\n",
    "\n",
    "y_true_list = []\n",
    "y_score_list = []\n",
    "\n",
    "for p in predictions:\n",
    "    gt = p.gt_label.cpu().numpy() if hasattr(p.gt_label, 'cpu') else p.gt_label\n",
    "    score = p.pred_score.cpu().numpy() if hasattr(p.pred_score, 'cpu') else p.pred_score\n",
    "    y_true_list.append(gt)\n",
    "    y_score_list.append(score)\n",
    "\n",
    "y_true = np.concatenate(y_true_list)\n",
    "y_score = np.concatenate(y_score_list)\n",
    "\n",
    "normal_scores = y_score[y_true == 0]\n",
    "anomaly_scores = y_score[y_true == 1]\n",
    "\n",
    "scores_df = pd.DataFrame({\n",
    "    'score': np.concatenate([normal_scores, anomaly_scores]),\n",
    "    'label': ['Normal'] * len(normal_scores) + ['Anomaly'] * len(anomaly_scores)\n",
    "})\n",
    "\n",
    "kde_plot(\n",
    "    scores_df,\n",
    "    col='score',\n",
    "    hue='label',\n",
    "    palette=['steelblue', 'salmon'],\n",
    "    title=f'{category}: Score Distribution',\n",
    "    xlabel='Anomaly Score'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a319f53",
   "metadata": {
    "id": "5a319f53"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    jaccard_score  # IoU\n",
    ")\n",
    "\n",
    "results = []\n",
    "for category, preds in all_predictions.items():\n",
    "    # Image-level\n",
    "    y_true = np.concatenate([p.gt_label.cpu().numpy() for p in preds])\n",
    "    y_score = np.concatenate([p.pred_score.cpu().numpy() for p in preds])\n",
    "    y_pred = (y_score >= 0.5).astype(int)\n",
    "\n",
    "    # Pixel-level\n",
    "    gt_masks = torch.cat([p.gt_mask for p in preds]).int()\n",
    "    pred_masks = torch.cat([(p.anomaly_map > 0.5).int() for p in preds])\n",
    "\n",
    "    metrics = {\n",
    "        \"Category\": category,\n",
    "        \"AUROC\": round(roc_auc_score(y_true, y_score), 4),\n",
    "        \"Accuracy\": round(accuracy_score(y_true, y_pred), 4),\n",
    "        \"Precision\": round(precision_score(y_true, y_pred, zero_division=0), 4),\n",
    "        \"Recall\": round(recall_score(y_true, y_pred, zero_division=0), 4),\n",
    "        \"F1\": round(f1_score(y_true, y_pred, zero_division=0), 4),\n",
    "        \"Dice\": round(\n",
    "            f1_score(\n",
    "                gt_masks.flatten().cpu().numpy(),\n",
    "                pred_masks.flatten().cpu().numpy(),\n",
    "                zero_division=0\n",
    "            ),\n",
    "            4\n",
    "        ),\n",
    "        \"IoU\": round(\n",
    "            jaccard_score(\n",
    "                gt_masks.flatten().numpy(),\n",
    "                pred_masks.flatten().numpy(),\n",
    "                average='binary',\n",
    "                zero_division=0\n",
    "            ),\n",
    "            4\n",
    "        ),\n",
    "        \"N_samples\": len(y_true)\n",
    "    }\n",
    "    results.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(results).set_index(\"Category\")\n",
    "avg_row = metrics_df.drop(columns=['N_samples']).mean().round(4)\n",
    "avg_row['N_samples'] = metrics_df['N_samples'].sum()\n",
    "metrics_df.loc['Average'] = avg_row\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8102244",
   "metadata": {
    "id": "f8102244"
   },
   "outputs": [],
   "source": [
    "from src.visual.plot import heatmap_plot\n",
    "\n",
    "metrics_trans = metrics_df.drop('Average').drop(columns='N_samples')\n",
    "heatmap_plot(\n",
    "    metrics_trans,\n",
    "    figsize=(10, 10),\n",
    "    cmap='RdYlGn',\n",
    "    annot=True,\n",
    "    fmt='.4f',\n",
    "    linewidths=0.5,\n",
    "    title='PatchCore Performance by Category',\n",
    "    rotation_x=45,\n",
    "    rotation_y=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bbd81",
   "metadata": {
    "id": "da3bbd81"
   },
   "outputs": [],
   "source": [
    "from src.visual.plot import anomaly_grid_from_dir\n",
    "\n",
    "for category in categories:\n",
    "    OUTPUT_IMG_ROOT = OUTPUT_ROOT / \"Patchcore\" / \"MVTecAD\" / category / \"latest\" / \"images\"\n",
    "    print(f\"{category}\")\n",
    "    anomaly_grid_from_dir(OUTPUT_IMG_ROOT, n_samples=1, n_cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b6060",
   "metadata": {
    "id": "383b6060"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
